{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Generative Adversial Networks to Colorize Greyscale Images\n",
    "\n",
    "### Abdul Matin, Marty Wang, Max Rosoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with the standard imports. Everything from the tools needed to access the graphics card to graphing styles is here. In addition, we import timing utilities, progress trackers, and we filter out python warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display, HTML\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import color\n",
    "\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In the next few cells, we setup the tools needed to run the notebook. We handle specific randomization for reproducability, as well as initialize the graphics card. To turn on the card, leave as is, otherwise, you can override the cuda variable to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = random.randint(1, 10000)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "print()\n",
    "print(\"Seed:\", manualSeed)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "print()\n",
    "print(\"Running On Cuda:\", cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "\n",
    "Next, we extend the Dataset class to handle the conversion to the LAB colorspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, paths, size):\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((size, size), Image.BICUBIC),\n",
    "            transforms.CenterCrop(size),\n",
    "        ])\n",
    "        \n",
    "        self.size = size\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = np.array(self.transforms(img) if hasattr(self, 'transforms') else img)\n",
    "        img_lab = color.rgb2lab(img).astype(\"float32\")\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        l = img_lab[[0], ...] / 50 - 1\n",
    "        ab = img_lab[[1, 2], ...] / 110\n",
    "        \n",
    "        return {'L': l, 'ab': ab}\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.paths)\n",
    "\n",
    "def make_dataloaders(batch_size=50, n_workers=os.cpu_count(), **kwargs):\n",
    "    \n",
    "    dataset = ColorizationDataset(size=256, **kwargs)\n",
    "    return DataLoader(dataset, batch_size=batch_size, num_workers=n_workers if device == 'cpu' else 0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False, innermost=False, outermost=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.outermost = outermost\n",
    "        if input_c is None: input_c = nf\n",
    "        \n",
    "        downconv = nn.Conv2d(input_c, ni, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(ni)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = nn.BatchNorm2d(nf)\n",
    "        \n",
    "        if outermost:\n",
    "            \n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        \n",
    "        elif innermost:\n",
    "            \n",
    "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.outermost:\n",
    "            \n",
    "            return self.model(x)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
    "        \n",
    "        super().__init__()\n",
    "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
    "        \n",
    "        for _ in range(n_down - 5):\n",
    "            \n",
    "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
    "       \n",
    "        out_filters = num_filters * 8\n",
    "        \n",
    "        for _ in range(3):\n",
    "            \n",
    "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
    "            out_filters //= 2\n",
    "        \n",
    "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        \n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) for i in range(n_down)]\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]                                                                 \n",
    "        self.model = nn.Sequential(*model)                                                   \n",
    "        \n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
    "        \n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "   \n",
    "    def __init__(self, loss, real_label=1.0, fake_label=0.0):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        self.loss = loss\n",
    "    \n",
    "    def __call__(self, preds, target_is_real):\n",
    "        \n",
    "        labels = (self.real_label if target_is_real else self.fake_label).expand_as(preds)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Model\n",
    "\n",
    "Here we put it all together and create the basis of our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, net_G, loss, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        if net_G is None:\n",
    "            \n",
    "            self.net_G = init_weights(Unet(input_c=1, output_c=2, n_down=8, num_filters=64).to(device))\n",
    "       \n",
    "        else:\n",
    "            \n",
    "            self.net_G = net_G.to(self.device)\n",
    "            \n",
    "        self.net_D = init_weights(PatchDiscriminator(input_c=3, n_down=3, num_filters=64).to(device))\n",
    "        \n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "        \n",
    "        self.GANcriterion = GANLoss(loss=loss).to(device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        \n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            \n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def setup_input(self, data):\n",
    "        \n",
    "        self.L = data['L'].to(device)\n",
    "        self.ab = data['ab'].to(device)\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        self.fake_color = self.net_G(self.L)\n",
    "    \n",
    "    def backward_D(self):\n",
    "        \n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "    \n",
    "    def backward_G(self):\n",
    "        \n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def optimize(self):\n",
    "        \n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, gain=0.02):\n",
    "    \n",
    "    def init_func(m):\n",
    "        \n",
    "        classname = m.__class__.__name__\n",
    "        \n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            \n",
    "            nn.init.normal_(m.weight.data, mean=0, std=gain)\n",
    "            \n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                \n",
    "                nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            \n",
    "            nn.init.normal_(m.weight.data, 1, gain)\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "            \n",
    "    net.apply(init_func)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_to_rgb(L, ab):\n",
    "    \n",
    "    Lab = torch.cat([(L + 1) * 50, ab * 110], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    return np.stack([color.lab2rgb(img) for img in Lab], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, data):\n",
    "    \n",
    "    model.net_G.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "       \n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    \n",
    "    model.net_G.train()\n",
    "    grey = model.L\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    fake_imgs = lab_to_rgb(grey, fake_color)\n",
    "    real_imgs = lab_to_rgb(grey, real_color)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 8))\n",
    "    rows = ['Greyscale', 'Generated', 'Real']\n",
    "    \n",
    "    for ax, row in zip(axes[:, 0], rows):\n",
    "        \n",
    "        ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - 20, 0), xycoords=ax.yaxis.label, textcoords='offset points', size='large', ha='right', va='center')\n",
    "        \n",
    "    for i in range(5):\n",
    "    \n",
    "        axes[i // 5][i].imshow(grey[i][0].cpu(), cmap='gray')\n",
    "        axes[(i + 5) // 5][i].imshow(fake_imgs[i])\n",
    "        axes[(i + 10) // 5][i].imshow(real_imgs[i])\n",
    "        \n",
    "        axes[i // 5][i].get_xaxis().set_ticks([])\n",
    "        axes[i // 5][i].get_yaxis().set_ticks([])\n",
    "        \n",
    "        axes[(i + 5) // 5][i].get_xaxis().set_ticks([])\n",
    "        axes[(i + 5) // 5][i].get_yaxis().set_ticks([])\n",
    "        \n",
    "        axes[(i + 10) // 5][i].get_xaxis().set_ticks([])\n",
    "        axes[(i + 10) // 5][i].get_yaxis().set_ticks([])\n",
    "        \n",
    "    fig.subplots_adjust(left=0.15, top=0.95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, net_G=None, loss=nn.MSELoss(), verbose=False):\n",
    "    \n",
    "    model = MainModel(net_G=net_G, loss=loss)\n",
    "    \n",
    "    generator_loss = []\n",
    "    discriminator_loss = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        time_remaining = (time.time() - start_time) / (epoch + 1) * (epochs - epoch + 1)\n",
    "        time_remaining_minutes = int(time_remaining // 60)\n",
    "        time_remaining_seconds = int((time_remaining / 60 - time_remaining_minutes) * 60)\n",
    "        \n",
    "        print()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\", end=\"\\t\")\n",
    "        \n",
    "        if time_remaining_minutes > 0:\n",
    "        \n",
    "            print(f\"Time Remaining: {time_remaining_minutes} minutes and {time_remaining_seconds} seconds\")\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            print(f\"Time Remaining: {time_remaining_seconds} seconds\")\n",
    "\n",
    "        \n",
    "        for data in tqdm(train_dl):\n",
    "            \n",
    "            model.setup_input(data) \n",
    "            model.optimize()\n",
    "            \n",
    "            g_loss = getattr(model, 'loss_G')\n",
    "            d_loss = getattr(model, 'loss_D')\n",
    "            \n",
    "            generator_loss.append(g_loss)\n",
    "            discriminator_loss.append(d_loss)\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print()\n",
    "\n",
    "    if verbose:        \n",
    "\n",
    "        run_time = time.time() - start_time\n",
    "        time_minutes = int(run_time // 60)\n",
    "        time_seconds = int((run_time / 60 - time_minutes) * 60)\n",
    "                      \n",
    "        if time_minutes > 0:\n",
    "        \n",
    "            print(f\"Training Time: {time_minutes} minutes and {time_seconds} seconds\")\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            print(f\"Training Time: {time_seconds} seconds\")\n",
    "        \n",
    "        print(\"On Device:\", \"GPU\" if cuda else \"CPU\")\n",
    "        print(\"Image Subset Size:\", image_subset)\n",
    "        print(\"Epochs:\", epochs)\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.title(\"Loss During Training\", fontsize=20, pad=20)\n",
    "        \n",
    "        plt.plot(generator_loss, label=\"Generator\")\n",
    "        plt.plot(discriminator_loss, label=\"Discriminator\")\n",
    "       \n",
    "        plt.xlabel(\"Iterations\", fontsize=15)\n",
    "        plt.ylabel(\"Loss\", fontsize=15)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = glob.glob(\"../../Data/Colorization/train/*.JPEG\")\n",
    "test = glob.glob(\"../../Data/Colorization/test/*.JPEG\")\n",
    "\n",
    "print()\n",
    "print(\"Training Images:\", len(train))\n",
    "print(\"Test Images:\", len(test))\n",
    "print()\n",
    "\n",
    "train_dl = make_dataloaders(paths=train)\n",
    "test_dl = make_dataloaders(paths=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = train_model(25, loss=nn.BCEWithLogitsLoss(), verbose=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}