{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import color\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_path):\n",
    "    \n",
    "    out_np = np.asarray(Image.open(img_path))\n",
    "    \n",
    "    if(out_np.ndim == 2):\n",
    "        \n",
    "        out_np = np.tile(out_np[:, :, None], 3)\n",
    "    \n",
    "    return out_np\n",
    "\n",
    "\n",
    "def resize_img(img, HW=(256, 256), resample=3):\n",
    "    \n",
    "    return np.asarray(Image.fromarray(img).resize((HW[1],HW[0]), resample=resample))\n",
    "\n",
    "\n",
    "def preprocess_img(img_rgb_orig, HW=(256, 256), resample=3):\n",
    "\n",
    "    img_rgb_rs = resize_img(img_rgb_orig, HW=HW, resample=resample)\n",
    "    img_lab_rs = color.rgb2lab(img_rgb_rs)\n",
    "\n",
    "    img_l_rs = img_lab_rs[:, :, 0]\n",
    "    img_ab_rs = img_lab_rs[:, :, 1:]\n",
    "\n",
    "    tens_rs_l = torch.Tensor(img_l_rs)[None, None, :, :]\n",
    "    tens_rs_ab = torch.Tensor(np.moveaxis(img_ab_rs, 2, 0))[None, :, :, :]\n",
    "\n",
    "    return tens_rs_l, tens_rs_ab\n",
    "\n",
    "\n",
    "def get_files_in_dir(directory):\n",
    "\n",
    "    return [directory + \"/\" + filename for filename in os.listdir(directory) if os.path.isfile(directory + \"/\" + filename)]\n",
    "\n",
    "\n",
    "def load_images(filenames, use_gpu=False):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        \n",
    "        img = load_img(file)\n",
    "        (tens_l_rs, tens_ab_rs) = preprocess_img(img)\n",
    "\n",
    "        if(use_gpu):\n",
    "            \n",
    "            tens_l_rs = tens_l_rs.cuda()\n",
    "        \n",
    "        data.append((tens_l_rs.reshape(1, 256, 256), tens_ab_rs.reshape(2, 256, 256)))\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def separate_io(test_data):\n",
    "    \n",
    "    inputs = torch.cat([x for x, _ in test_data]).reshape(-1, 1, 256, 256)\n",
    "    outputs = torch.cat([y for _, y in test_data]).reshape(-1, 2, 256, 256)\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# custom loss function based on MSELoss. Slightly biased towards more extreme (colorful) values\n",
    "def MSEColorfulLoss(output, target):\n",
    "    \n",
    "    return torch.mean((output - target)**2 + 0.15 * torch.tanh(6*(torch.abs(target) - torch.abs(output) - 0.333)))\n",
    "\n",
    "class Colorizer(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Colorizer, self).__init__()\n",
    "        k = 3\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=7, stride=2, padding=7//2),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 64, kernel_size=5, stride=2, padding=5//2),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=k, stride=2, padding=k//2),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=k, stride=1, padding=k//2),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=k, stride=2, padding=k//2, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=k, stride=2, padding=k//2, output_padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=k, stride=2, padding=k//2, output_padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(16, 8, kernel_size=k, stride=1, padding=k//2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.layer9 = nn.Conv2d(8, 2, kernel_size=5, stride=1, padding=5//2)\n",
    "        \n",
    "        \n",
    "    # low level functionality\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        return out\n",
    "    \n",
    "    def use(self, x):\n",
    "        return self.forward((x-50)/100.0) * 110\n",
    "    \n",
    "    def test(self, x, y, criterion=MSEColorfulLoss):\n",
    "        return criterion(self.forward((x-50)/100.0), y / 110.0).item()\n",
    "        \n",
    "    def train(self, train_loader, learning_rate=0.1, num_epochs=10, criterion=None, optimizer=None):\n",
    "        \n",
    "        if criterion == None:\n",
    "            criterion = MSEColorfulLoss\n",
    "            \n",
    "        if optimizer == None:\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        total_step = len(train_loader)\n",
    "        loss_list = []\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, expected) in enumerate(train_loader):\n",
    "                # Run the forward pass\n",
    "                outputs = self.forward((images-50)/100.0)\n",
    "                loss = criterion(outputs, expected / 110.0)\n",
    "                loss_list.append(loss.item())\n",
    "\n",
    "                # Backprop and perform Adam optimisation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if ((epoch + 1) % 10 == 0 or num_epochs < 5) and i == 0:\n",
    "                    print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                          .format(epoch + 1, num_epochs, loss.item()))\n",
    "                    \n",
    "    def save(self, filename=\"model_weights.pt\"):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        \n",
    "    def load(self, filename=\"model_weights.pt\"):\n",
    "        self.load_state_dict(torch.load(filename))\n",
    "        #self.eval()\n",
    "        \n",
    "        \n",
    "    # high level functionality\n",
    "    \n",
    "    # trains from images within a directory (not subdirectories), and optionally returns loss from a test set\n",
    "    def train_from_dir(self, train_dir, test_dir=None, learning_rate=0.001, num_epochs=200, batch_size=10, criterion=None, model_filename=None):\n",
    "        train_data = load_images(get_files_in_dir(train_dir))\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        self.train(train_loader, learning_rate=learning_rate, num_epochs=num_epochs, criterion=criterion)\n",
    "        \n",
    "        if (model_filename != None):\n",
    "            self.save(model_filename)\n",
    "        \n",
    "        \n",
    "        if (test_dir != None):\n",
    "            test_x, test_y = separate_io(load_images(get_files_in_dir(test_dir)))\n",
    "            return self.test(test_x, test_y)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights_file=\"flower_colorizer_rmse.pt\"\n",
    "\n",
    "model = Colorizer()\n",
    "\n",
    "if path.exists(weights_file):\n",
    "    \n",
    "    #load model from file\n",
    "    model.load(weights_file)\n",
    "    \n",
    "else:\n",
    "    model.train_from_dir(\"../../Data/Colorization/train\", learning_rate=0.001, num_epochs=200, batch_size=100, model_filename=weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.colorize(\"imgs/test_flower_01.jpg\", \"out_imgs/test_flower_01_colorized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.colorize(\"imgs/test_flower_01.jpg\", \"out_imgs/test_flower_01_colorized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.colorize(\"imgs/test_flower_02.jpg\", \"out_imgs/test_flower_02_colorized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.colorize(\"imgs/test_flower_03.jpg\", \"out_imgs/test_flower_03_colorized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.colorize(\"imgs/test_flower_04.jpg\", \"out_imgs/test_flower_04_colorized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}